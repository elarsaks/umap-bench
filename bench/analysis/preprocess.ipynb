{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# UMAP Benchmark: Preprocess Results\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook preprocesses UMAP benchmark results by flattening nested JSON files into a single tabular CSV format suitable for statistical analysis. \n",
        "\n",
        "**Key Features:**\n",
        "- Extracts performance metrics from benchmark runs\n",
        "- Combines machine metadata, git information, and UI performance data\n",
        "- Automatically filters out incomplete results (missing UI metrics or empty rows)\n",
        "- Outputs a clean, analysis-ready CSV file\n",
        "\n",
        "**Input:** Multiple JSON files in `../results/` following the pattern `bench-runs-*.json`\n",
        "\n",
        "**Output:** `../outputs/preprocessed.csv` with all benchmark data in tabular format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cd59e1c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Paths relative to bench/analysis/ folder\n",
        "results_dir = \"../results\"\n",
        "output_path = \"../outputs/preprocessed.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd00ae75",
      "metadata": {},
      "source": [
        "## Setup and Configuration\n",
        "\n",
        "Import required libraries and configure paths:\n",
        "- `results_dir`: Directory containing benchmark JSON files\n",
        "- `output_path`: Path for the output CSV file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8284c73f",
      "metadata": {},
      "source": [
        "## Data Processing\n",
        "\n",
        "The following cell processes each benchmark JSON file and extracts:\n",
        "\n",
        "1. **Top-level metadata**: Generation time, run count, WASM configuration\n",
        "2. **Machine information**: Platform, CPU, memory, load averages\n",
        "3. **Git context**: Commit hash, branch, dirty status\n",
        "4. **Result metrics**: Run number, duration\n",
        "5. **Performance data**: Runtime, memory usage, trustworthiness, FPS, responsiveness\n",
        "\n",
        "Each metric row (one per dataset) becomes a separate record in the output, with all parent context preserved.\n",
        "\n",
        "Note: Supports both the new flat `metrics[]` format and the legacy `uiMetrics[].rows[]` format for backward compatibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5662f4c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "rows = []\n",
        "files = sorted(glob.glob(os.path.join(results_dir, \"bench-runs-*.json\")))\n",
        "\n",
        "for path in files:\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    top = {\n",
        "        \"generated_at\": data.get(\"generatedAt\"),\n",
        "        \"runs_declared\": data.get(\"runs\"),\n",
        "        \"wasm_features_file\": data.get(\"wasmFeatures\"),\n",
        "        \"wasm_preload\": data.get(\"wasmPreload\"),\n",
        "    }\n",
        "\n",
        "    machine = data.get(\"machine\") or {}\n",
        "    top.update({\n",
        "        \"machine_platform\": machine.get(\"platform\"),\n",
        "        \"machine_release\": machine.get(\"release\"),\n",
        "        \"machine_arch\": machine.get(\"arch\"),\n",
        "        \"cpu_model\": machine.get(\"cpuModel\"),\n",
        "        \"cpu_cores\": machine.get(\"cpuCores\"),\n",
        "        \"total_mem_bytes\": machine.get(\"totalMemBytes\"),\n",
        "        \"load_avg_1\": (machine.get(\"loadAvg\") or [None, None, None])[0],\n",
        "        \"load_avg_5\": (machine.get(\"loadAvg\") or [None, None, None])[1],\n",
        "        \"load_avg_15\": (machine.get(\"loadAvg\") or [None, None, None])[2],\n",
        "        \"hostname\": machine.get(\"hostname\"),\n",
        "    })\n",
        "\n",
        "    git = data.get(\"git\") or {}\n",
        "    top.update({\n",
        "        \"git_commit\": git.get(\"commit\"),\n",
        "        \"git_branch\": git.get(\"branch\"),\n",
        "        \"git_status_dirty\": git.get(\"statusDirty\"),\n",
        "    })\n",
        "\n",
        "    for result in data.get(\"results\", []):\n",
        "        # Support both old format (uiMetrics[].rows[]) and new format (metrics[])\n",
        "        metrics_list = result.get(\"metrics\")\n",
        "        if metrics_list is None:\n",
        "            # Old format fallback\n",
        "            ui_metrics = result.get(\"uiMetrics\") or []\n",
        "            metrics_list = []\n",
        "            for ui in ui_metrics:\n",
        "                metrics_list.extend(ui.get(\"rows\") or [])\n",
        "        \n",
        "        if not metrics_list:\n",
        "            continue\n",
        "            \n",
        "        base = dict(top)\n",
        "        base.update({\n",
        "            \"result_run\": result.get(\"run\"),\n",
        "            \"result_duration_ms\": result.get(\"durationMs\"),\n",
        "        })\n",
        "\n",
        "        stats = result.get(\"stats\") or {}\n",
        "        base.update({\n",
        "            \"stats_start_time\": stats.get(\"startTime\"),\n",
        "            \"stats_duration_ms\": stats.get(\"duration\"),\n",
        "        })\n",
        "\n",
        "        for row in metrics_list:\n",
        "            # Do not infer renderingEnabled. If missing, default to False.\n",
        "            rendering_enabled = row.get(\"renderingEnabled\")\n",
        "            if rendering_enabled is None:\n",
        "                rendering_enabled = False\n",
        "            \n",
        "            out = dict(base)\n",
        "            out.update({\n",
        "                \"dataset_index\": row.get(\"datasetIndex\") or row.get(\"runId\"),  # Support old field name\n",
        "                \"timestamp\": row.get(\"timestamp\"),\n",
        "                \"dataset_name\": row.get(\"datasetName\"),\n",
        "                \"dataset_size\": row.get(\"datasetSize\"),\n",
        "                \"dimensions\": row.get(\"dimensions\"),\n",
        "                \"wasm_features\": row.get(\"wasmFeatures\"),\n",
        "                \"rendering_enabled\": rendering_enabled,\n",
        "                \"runtime_ms\": row.get(\"runtimeMs\"),\n",
        "                \"memory_delta_mb\": row.get(\"memoryDeltaMb\"),\n",
        "                \"trustworthiness\": row.get(\"trustworthiness\"),\n",
        "                \"fps_avg\": row.get(\"fpsAvg\"),\n",
        "                \"responsiveness_ms\": row.get(\"responsivenessMs\"),\n",
        "            })\n",
        "            rows.append(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ec736c4",
      "metadata": {},
      "source": [
        "## Processing Summary\n",
        "\n",
        "Review the data extraction results:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "018fb38e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files processed: 25\n",
            "Total rows extracted: 500\n",
            "\n",
            "Sample of first row keys:\n",
            "  - generated_at\n",
            "  - runs_declared\n",
            "  - wasm_features_file\n",
            "  - wasm_preload\n",
            "  - machine_platform\n",
            "  - machine_release\n",
            "  - machine_arch\n",
            "  - cpu_model\n",
            "  - cpu_cores\n",
            "  - total_mem_bytes\n"
          ]
        }
      ],
      "source": [
        "print(f\"Files processed: {len(files)}\")\n",
        "print(f\"Total rows extracted: {len(rows)}\")\n",
        "print(f\"\\nSample of first row keys:\")\n",
        "if rows:\n",
        "    for key in list(rows[0].keys())[:10]:\n",
        "        print(f\"  - {key}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efb2ca1e",
      "metadata": {},
      "source": [
        "## Create DataFrame and Export\n",
        "\n",
        "Convert the extracted rows into a pandas DataFrame with a consistent column order, then export to CSV. The output file will be ready for statistical analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c3f99755",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Successfully saved 500 rows to '../outputs/preprocessed.csv'\n",
            "\n",
            "DataFrame shape: (500, 33)\n",
            "Columns: 33\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generated_at</th>\n",
              "      <th>runs_declared</th>\n",
              "      <th>result_run</th>\n",
              "      <th>result_duration_ms</th>\n",
              "      <th>stats_start_time</th>\n",
              "      <th>stats_duration_ms</th>\n",
              "      <th>wasm_features_file</th>\n",
              "      <th>wasm_preload</th>\n",
              "      <th>machine_platform</th>\n",
              "      <th>machine_release</th>\n",
              "      <th>...</th>\n",
              "      <th>dataset_name</th>\n",
              "      <th>dataset_size</th>\n",
              "      <th>dimensions</th>\n",
              "      <th>wasm_features</th>\n",
              "      <th>rendering_enabled</th>\n",
              "      <th>runtime_ms</th>\n",
              "      <th>memory_delta_mb</th>\n",
              "      <th>trustworthiness</th>\n",
              "      <th>fps_avg</th>\n",
              "      <th>responsiveness_ms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2026-02-07T03:48:51.452Z</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>40567</td>\n",
              "      <td>2026-02-07T03:49:07.248Z</td>\n",
              "      <td>25205.813</td>\n",
              "      <td>none</td>\n",
              "      <td>True</td>\n",
              "      <td>linux</td>\n",
              "      <td>6.6.87.2-microsoft-standard-WSL2</td>\n",
              "      <td>...</td>\n",
              "      <td>Iris Dataset (150 points, 4D)</td>\n",
              "      <td>150</td>\n",
              "      <td>4</td>\n",
              "      <td>none</td>\n",
              "      <td>True</td>\n",
              "      <td>2366.1</td>\n",
              "      <td>-0.013417</td>\n",
              "      <td>0.987833</td>\n",
              "      <td>60.039370</td>\n",
              "      <td>8.281818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2026-02-07T03:48:51.452Z</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>40567</td>\n",
              "      <td>2026-02-07T03:49:07.248Z</td>\n",
              "      <td>25205.813</td>\n",
              "      <td>none</td>\n",
              "      <td>True</td>\n",
              "      <td>linux</td>\n",
              "      <td>6.6.87.2-microsoft-standard-WSL2</td>\n",
              "      <td>...</td>\n",
              "      <td>Small Random (80 points)</td>\n",
              "      <td>80</td>\n",
              "      <td>10</td>\n",
              "      <td>none</td>\n",
              "      <td>True</td>\n",
              "      <td>3326.6</td>\n",
              "      <td>15.658463</td>\n",
              "      <td>0.860789</td>\n",
              "      <td>47.216211</td>\n",
              "      <td>21.033333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2026-02-07T03:48:51.452Z</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>37428</td>\n",
              "      <td>2026-02-07T03:49:46.215Z</td>\n",
              "      <td>23675.601</td>\n",
              "      <td>none</td>\n",
              "      <td>True</td>\n",
              "      <td>linux</td>\n",
              "      <td>6.6.87.2-microsoft-standard-WSL2</td>\n",
              "      <td>...</td>\n",
              "      <td>Iris Dataset (150 points, 4D)</td>\n",
              "      <td>150</td>\n",
              "      <td>4</td>\n",
              "      <td>none</td>\n",
              "      <td>True</td>\n",
              "      <td>2392.7</td>\n",
              "      <td>-0.051042</td>\n",
              "      <td>0.987807</td>\n",
              "      <td>60.003935</td>\n",
              "      <td>8.709091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2026-02-07T03:48:51.452Z</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>37428</td>\n",
              "      <td>2026-02-07T03:49:46.215Z</td>\n",
              "      <td>23675.601</td>\n",
              "      <td>none</td>\n",
              "      <td>True</td>\n",
              "      <td>linux</td>\n",
              "      <td>6.6.87.2-microsoft-standard-WSL2</td>\n",
              "      <td>...</td>\n",
              "      <td>Small Random (80 points)</td>\n",
              "      <td>80</td>\n",
              "      <td>10</td>\n",
              "      <td>none</td>\n",
              "      <td>True</td>\n",
              "      <td>3021.8</td>\n",
              "      <td>8.784738</td>\n",
              "      <td>0.853083</td>\n",
              "      <td>48.190401</td>\n",
              "      <td>21.140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2026-02-07T03:48:51.452Z</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>36905</td>\n",
              "      <td>2026-02-07T03:50:23.352Z</td>\n",
              "      <td>23448.497</td>\n",
              "      <td>none</td>\n",
              "      <td>True</td>\n",
              "      <td>linux</td>\n",
              "      <td>6.6.87.2-microsoft-standard-WSL2</td>\n",
              "      <td>...</td>\n",
              "      <td>Iris Dataset (150 points, 4D)</td>\n",
              "      <td>150</td>\n",
              "      <td>4</td>\n",
              "      <td>none</td>\n",
              "      <td>True</td>\n",
              "      <td>2350.5</td>\n",
              "      <td>0.020347</td>\n",
              "      <td>0.987706</td>\n",
              "      <td>60.015742</td>\n",
              "      <td>8.490909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               generated_at  runs_declared  result_run  result_duration_ms  \\\n",
              "0  2026-02-07T03:48:51.452Z             10           1               40567   \n",
              "1  2026-02-07T03:48:51.452Z             10           1               40567   \n",
              "2  2026-02-07T03:48:51.452Z             10           2               37428   \n",
              "3  2026-02-07T03:48:51.452Z             10           2               37428   \n",
              "4  2026-02-07T03:48:51.452Z             10           3               36905   \n",
              "\n",
              "           stats_start_time  stats_duration_ms wasm_features_file  \\\n",
              "0  2026-02-07T03:49:07.248Z          25205.813               none   \n",
              "1  2026-02-07T03:49:07.248Z          25205.813               none   \n",
              "2  2026-02-07T03:49:46.215Z          23675.601               none   \n",
              "3  2026-02-07T03:49:46.215Z          23675.601               none   \n",
              "4  2026-02-07T03:50:23.352Z          23448.497               none   \n",
              "\n",
              "   wasm_preload machine_platform                   machine_release  ...  \\\n",
              "0          True            linux  6.6.87.2-microsoft-standard-WSL2  ...   \n",
              "1          True            linux  6.6.87.2-microsoft-standard-WSL2  ...   \n",
              "2          True            linux  6.6.87.2-microsoft-standard-WSL2  ...   \n",
              "3          True            linux  6.6.87.2-microsoft-standard-WSL2  ...   \n",
              "4          True            linux  6.6.87.2-microsoft-standard-WSL2  ...   \n",
              "\n",
              "                    dataset_name dataset_size  dimensions  wasm_features  \\\n",
              "0  Iris Dataset (150 points, 4D)          150           4           none   \n",
              "1       Small Random (80 points)           80          10           none   \n",
              "2  Iris Dataset (150 points, 4D)          150           4           none   \n",
              "3       Small Random (80 points)           80          10           none   \n",
              "4  Iris Dataset (150 points, 4D)          150           4           none   \n",
              "\n",
              "   rendering_enabled  runtime_ms  memory_delta_mb trustworthiness    fps_avg  \\\n",
              "0               True      2366.1        -0.013417        0.987833  60.039370   \n",
              "1               True      3326.6        15.658463        0.860789  47.216211   \n",
              "2               True      2392.7        -0.051042        0.987807  60.003935   \n",
              "3               True      3021.8         8.784738        0.853083  48.190401   \n",
              "4               True      2350.5         0.020347        0.987706  60.015742   \n",
              "\n",
              "  responsiveness_ms  \n",
              "0          8.281818  \n",
              "1         21.033333  \n",
              "2          8.709091  \n",
              "3         21.140000  \n",
              "4          8.490909  \n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "columns = [\n",
        "    # File/run metadata\n",
        "    \"generated_at\",\n",
        "    \"runs_declared\",\n",
        "    \"result_run\",\n",
        "    \"result_duration_ms\",\n",
        "    \"stats_start_time\",\n",
        "    \"stats_duration_ms\",\n",
        "    # WASM config (file-level)\n",
        "    \"wasm_features_file\",\n",
        "    \"wasm_preload\",\n",
        "    # Machine info\n",
        "    \"machine_platform\",\n",
        "    \"machine_release\",\n",
        "    \"machine_arch\",\n",
        "    \"cpu_model\",\n",
        "    \"cpu_cores\",\n",
        "    \"total_mem_bytes\",\n",
        "    \"load_avg_1\",\n",
        "    \"load_avg_5\",\n",
        "    \"load_avg_15\",\n",
        "    \"hostname\",\n",
        "    # Git context\n",
        "    \"git_commit\",\n",
        "    \"git_branch\",\n",
        "    \"git_status_dirty\",\n",
        "    # Per-dataset metrics (the core data)\n",
        "    \"dataset_index\",\n",
        "    \"timestamp\",\n",
        "    \"dataset_name\",\n",
        "    \"dataset_size\",\n",
        "    \"dimensions\",\n",
        "    \"wasm_features\",\n",
        "    \"rendering_enabled\",\n",
        "    \"runtime_ms\",\n",
        "    \"memory_delta_mb\",\n",
        "    \"trustworthiness\",\n",
        "    \"fps_avg\",\n",
        "    \"responsiveness_ms\",\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(rows).reindex(columns=columns)\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "\n",
        "df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"✓ Successfully saved {len(df)} rows to '{output_path}'\")\n",
        "print(f\"\\nDataFrame shape: {df.shape}\")\n",
        "print(f\"Columns: {len(df.columns)}\")\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59223742",
      "metadata": {},
      "source": [
        "## Data Standardization and Cleaning\n",
        "\n",
        "Prepare the dataset for analysis by:\n",
        "- Standardizing WASM feature names into readable labels\n",
        "- Mapping machine platforms to identifiable types\n",
        "- Converting all numeric columns to proper types\n",
        "- Removing rows with missing critical values\n",
        "- Creating a clean analysis-ready dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f351db42",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Dataset ready: 500 measurements (dropped 0 rows)\n",
            "Features: ['All Features', 'Baseline (JS)', 'Distance', 'Matrix', 'NN Descent', 'Optimizer', 'Tree']\n",
            "Datasets: 6\n",
            "\n",
            "Measurements per feature:\n",
            "feature_name\n",
            "All Features     100\n",
            "Baseline (JS)     60\n",
            "Distance          60\n",
            "Matrix            60\n",
            "NN Descent        60\n",
            "Optimizer        100\n",
            "Tree              60\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Standardize column names and prepare data\n",
        "df_clean = df.copy()\n",
        "\n",
        "# Create standardized feature column\n",
        "if 'wasm_features' in df_clean.columns:\n",
        "    df_clean['feature'] = df_clean['wasm_features'].fillna('none').str.lower().str.strip()\n",
        "else:\n",
        "    df_clean['feature'] = df_clean.get('feature', 'none')\n",
        "\n",
        "# Map comma-separated features to 'all'\n",
        "df_clean.loc[df_clean['feature'].astype(str).str.contains(',', na=False), 'feature'] = 'all'\n",
        "\n",
        "# Standardize feature names\n",
        "feature_map = {\n",
        "    'none': 'Baseline (JS)',\n",
        "    'dist': 'Distance',\n",
        "    'tree': 'Tree',\n",
        "    'matrix': 'Matrix',\n",
        "    'nn': 'NN Descent',\n",
        "    'opt': 'Optimizer',\n",
        "    'all': 'All Features'\n",
        "}\n",
        "df_clean['feature_name'] = df_clean['feature'].map(feature_map).fillna(df_clean['feature'])\n",
        "\n",
        "# Identify machine types\n",
        "if 'machine_platform' in df_clean.columns:\n",
        "    platform_map = {'darwin': 'MacBook', 'linux': 'Linux'}\n",
        "    df_clean['machine_type'] = df_clean['machine_platform'].map(platform_map).fillna(df_clean['machine_platform'])\n",
        "else:\n",
        "    if 'machine_type' not in df_clean.columns:\n",
        "        df_clean['machine_type'] = pd.NA\n",
        "\n",
        "# Convert numeric columns\n",
        "numeric_cols = ['runtime_ms', 'memory_delta_mb', 'trustworthiness', 'fps_avg', 'responsiveness_ms']\n",
        "for col in numeric_cols:\n",
        "    if col in df_clean.columns:\n",
        "        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
        "\n",
        "# Remove missing values in key columns\n",
        "before = len(df_clean)\n",
        "required = [c for c in ['runtime_ms', 'feature_name'] if c in df_clean.columns]\n",
        "df_clean = df_clean.dropna(subset=required)\n",
        "dropped = before - len(df_clean)\n",
        "\n",
        "# Create analysis dataset\n",
        "df_analysis = df_clean.copy()\n",
        "\n",
        "# Define standard feature order\n",
        "feature_order = ['Baseline (JS)', 'Distance', 'Tree', 'Matrix', 'NN Descent', 'Optimizer', 'All Features']\n",
        "feature_order = [f for f in feature_order if f in df_analysis['feature_name'].unique()]\n",
        "\n",
        "print(f\"✓ Dataset ready: {len(df_analysis):,} measurements (dropped {dropped} rows)\")\n",
        "print(f\"Features: {sorted(df_analysis['feature_name'].unique())}\")\n",
        "print(f\"Datasets: {df_analysis['dataset_name'].nunique()}\")\n",
        "print(f\"\\nMeasurements per feature:\")\n",
        "print(df_analysis['feature_name'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ea85cae0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Saved cleaned dataset to '../outputs/preprocessed.csv'\n",
            "  Rows: 500\n",
            "  Added columns: feature, feature_name, machine_type\n"
          ]
        }
      ],
      "source": [
        "# Save cleaned analysis-ready dataset\n",
        "output_cleaned_path = \"../outputs/preprocessed.csv\"\n",
        "df_analysis.to_csv(output_cleaned_path, index=False)\n",
        "\n",
        "print(f\"✓ Saved cleaned dataset to '{output_cleaned_path}'\")\n",
        "print(f\"  Rows: {len(df_analysis):,}\")\n",
        "print(f\"  Added columns: feature, feature_name, machine_type\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "umap-bench",
      "language": "python",
      "name": "umap-bench"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
